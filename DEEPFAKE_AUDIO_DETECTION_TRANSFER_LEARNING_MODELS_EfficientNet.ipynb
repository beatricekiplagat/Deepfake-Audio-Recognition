{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEEPFAKE AUDIO DETECTION TRANSFER LEARNING MODELS -  EfficientNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beatricekiplagat/Deepfake-Audio-Recognition/blob/dev_branch/DEEPFAKE_AUDIO_DETECTION_TRANSFER_LEARNING_MODELS_EfficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5SsA2I3duKx"
      },
      "source": [
        "Dataset Preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9MFWrLxd1V6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8b2dd0-1088-49d8-a51a-5fc37808edb4"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.4.1)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.24)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoCd-J1D9ksd",
        "outputId": "4f7fc355-a045-46a6-d7ea-2cb03caef819"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHfP0tmSdRCZ",
        "outputId": "eebe5ea2-b9b5-4277-cd80-25f3756e84b5"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "dataset_path = os.listdir('/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Train')\n",
        "\n",
        "print (dataset_path)  #what kinds of classes are in this dataset\n",
        "\n",
        "print(\"Types of classes labels found: \", len(dataset_path))\n",
        "\n",
        "class_labels = []\n",
        "\n",
        "for item in dataset_path:\n",
        " # Get all the file names\n",
        " all_classes = os.listdir('/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Train' + '/' +item)\n",
        " #print(all_classes)\n",
        "\n",
        " # Add them to the list\n",
        " for room in all_classes:\n",
        "    class_labels.append((item, str('dataset_path' + '/' +item) + '/' + room))\n",
        "    #print(class_labels[:5])\n",
        "    \n",
        "    \n",
        "# Build a dataframe        \n",
        "df = pd.DataFrame(data=class_labels, columns=['Labels', 'image'])\n",
        "print(df.head())\n",
        "print(df.tail())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Spoof', 'Bonafide']\n",
            "Types of classes labels found:  2\n",
            "  Labels                                image\n",
            "0  Spoof  dataset_path/Spoof/LA_D_7121651.png\n",
            "1  Spoof  dataset_path/Spoof/LA_D_7212590.png\n",
            "2  Spoof  dataset_path/Spoof/LA_D_6131320.png\n",
            "3  Spoof  dataset_path/Spoof/LA_D_6692719.png\n",
            "4  Spoof  dataset_path/Spoof/LA_D_8380959.png\n",
            "        Labels                                           image\n",
            "1645  Bonafide  dataset_path/Bonafide/Copy of LA_D_5945817.png\n",
            "1646  Bonafide  dataset_path/Bonafide/Copy of LA_D_1696066.png\n",
            "1647  Bonafide  dataset_path/Bonafide/Copy of LA_D_5226379.png\n",
            "1648  Bonafide  dataset_path/Bonafide/Copy of LA_D_3440131.png\n",
            "1649  Bonafide  dataset_path/Bonafide/Copy of LA_D_8126437.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDWI9SHB_cq-",
        "outputId": "524c2aa1-63d1-4533-e661-f570d04e1f2f"
      },
      "source": [
        "# Initialize wandb\n",
        "wandb.login()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mruoro\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "GL9GavCH_1Gj",
        "outputId": "dd1636bd-07d2-4ec2-a7ef-8f87bebad7ff"
      },
      "source": [
        "wandb.init(project='DeepFake Audio Detection', entity='ruoro', save_code=True, \n",
        "           config = {\n",
        "               'learning_rate': 0.001,\n",
        "               'epochs': 7,\n",
        "               'batch_size' : 4,\n",
        "               'loss_function' : 'binary_crossentropy'\n",
        "           })"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">spring-rain-46</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ruoro/DeepFake%20Audio%20Detection\" target=\"_blank\">https://wandb.ai/ruoro/DeepFake%20Audio%20Detection</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/ruoro/DeepFake%20Audio%20Detection/runs/2lxbz50p\" target=\"_blank\">https://wandb.ai/ruoro/DeepFake%20Audio%20Detection/runs/2lxbz50p</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210924_075520-2lxbz50p</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fe408feea90>"
            ],
            "text/html": [
              "<h1>Run(2lxbz50p)</h1><iframe src=\"https://wandb.ai/ruoro/DeepFake%20Audio%20Detection/runs/2lxbz50p\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO4tdc1UeRMc",
        "outputId": "eb323877-4679-4731-db2d-54badef9d7a4"
      },
      "source": [
        "\n",
        "# Let's check how many samples for each category are present\n",
        "print(\"Total number of images in the dataset: \", len(df))\n",
        "\n",
        "label_count = df['Labels'].value_counts()\n",
        "print(label_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images in the dataset:  1650\n",
            "Bonafide    851\n",
            "Spoof       799\n",
            "Name: Labels, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUD28ky5eYSZ"
      },
      "source": [
        "import cv2\n",
        "path = '/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Train/'\n",
        "dataset_path = os.listdir('/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Train')\n",
        "\n",
        "im_size = 224\n",
        "\n",
        "labels = [] #os.listdir(path)\n",
        "images = [] #os.listdir(path + labels)\n",
        "\n",
        "\n",
        "for i in dataset_path:\n",
        "    data_path = path + str(i)  \n",
        "    filenames = [i for i in os.listdir(data_path) ]\n",
        "   \n",
        "    for f in filenames:\n",
        "        img = cv2.imread(data_path + '/' + f)\n",
        "        img = cv2.resize(img, (im_size, im_size))\n",
        "        images.append(img)\n",
        "        labels.append(i)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGKHiAT0_IbW",
        "outputId": "ab1025ae-6b89-42a4-8a59-444339d722c3"
      },
      "source": [
        "print(len(images))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tany_xBYtRph",
        "outputId": "1caf3dd3-7bfa-4548-d9aa-69b6bdd3d77d"
      },
      "source": [
        "#This model takes input images of shape (224, 224, 3), and the input data should range [0, 255]. \n",
        "\n",
        "images = np.array(images)\n",
        "\n",
        "images = images.astype('float32') / 255.0\n",
        "images.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1650, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVr8QN9EtZ99",
        "outputId": "549a3821-32b5-43b8-f052-9ac5dd95103f"
      },
      "source": [
        "#Pre-processing the data. We need to perform label encoding in order to get the model to work\n",
        "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
        "y=df['Labels'].values\n",
        "print(y)\n",
        "\n",
        "y_labelencoder = LabelEncoder ()\n",
        "y = y_labelencoder.fit_transform (y)\n",
        "print (y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Spoof' 'Spoof' 'Spoof' ... 'Bonafide' 'Bonafide' 'Bonafide']\n",
            "[1 1 1 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFUmJm-Ktgbv",
        "outputId": "7e66910f-9689-4ec0-8b67-c161522cff33"
      },
      "source": [
        "y=y.reshape(-1,1)\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "ct = ColumnTransformer([('my_ohe', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "Y = ct.fit_transform(y) #.toarray()\n",
        "print(Y[:5])\n",
        "print(Y[35:])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tem1hzumtlb_",
        "outputId": "f937381a-9e31-4b44-dbef-a7e6cec2409d"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "images, Y = shuffle(images, Y, random_state=1)\n",
        "\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.15, random_state=42)\n",
        "\n",
        "#inpect the shape of the training and testing.\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1402, 224, 224, 3)\n",
            "(1402, 2)\n",
            "(248, 224, 224, 3)\n",
            "(248, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oieEbV5-uVcr"
      },
      "source": [
        "EfficientNet Implementation :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwLSefLMt9FQ"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "NUM_CLASSES = 2\n",
        "IMG_SIZE = 224\n",
        "size = (IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "# Using model without transfer learning\n",
        "\n",
        "outputs = EfficientNetB0(include_top=True, weights=None, classes=NUM_CLASSES)(inputs)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_1xuUgSr0tz",
        "outputId": "be47c4cd-8156-42b3-82dc-05adc96748fc"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory('/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Test',\n",
        "  target_size=(224, 224),\n",
        "  batch_size=4,\n",
        "  class_mode='categorical')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk7wC7Cnup5O",
        "outputId": "fb081bf2-497d-469c-9e0c-1504f002b9b1"
      },
      "source": [
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"] )\n",
        "\n",
        "model.summary()\n",
        "\n",
        "hist = model.fit(train_x, train_y, \n",
        "                 validation_data = (test_x,test_y),\n",
        "                 epochs=30,\n",
        "                 callbacks = [WandbCallback(data_type=\"image\", labels=labels, generator=validation_generator)],\n",
        "                 validation_steps= 20,\n",
        "                 verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, 2)                 4052133   \n",
            "=================================================================\n",
            "Total params: 4,052,133\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 42,023\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "44/44 - 47s - loss: 1.7705 - accuracy: 0.6605 - val_loss: 0.7264 - val_accuracy: 0.5484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30\n",
            "44/44 - 25s - loss: 0.6614 - accuracy: 0.7910 - val_loss: 1.1102 - val_accuracy: 0.5484\n",
            "Epoch 3/30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwsetnS7tc57"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# loss\n",
        "plt.plot(hist.history['loss'], label='train loss')\n",
        "plt.plot(hist.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddk1e9URvM4w"
      },
      "source": [
        "# accuracies\n",
        "plt.plot(hist.history['accuracy'], label='train accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], label='val accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "model.save('EffNetModel.pb')\n",
        "# model.save('EffNetModel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0RmvchXvT6j"
      },
      "source": [
        "preds = model.evaluate(test_x, test_y)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaBmQPRhALMx"
      },
      "source": [
        "run = wandb.init(project='DeepFake Audio Detection', entity='ruoro')\n",
        "model = wandb.Artifact('effnetmodel', type='model')\n",
        "model.add_file('EffNetModel.h5')\n",
        "\n",
        "run.log_artifact(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIyUvh1uvdA8"
      },
      "source": [
        "TESTING MODEL ON UNSEEN DATA :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbNVwhVEvgC9"
      },
      "source": [
        "# from matplotlib.pyplot import imread\n",
        "from matplotlib.pyplot import imshow\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "\n",
        "# img_path = '/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Test/Spoof/LA_D_1115199.png'\n",
        "img_path = '/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Test/Bonafide/LA_D_1364611.png'\n",
        "#img = image.load_img(img_path, target_size=(224, 224))\n",
        "#x = img.img_to_array(img)\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.resize(img, (224, 224))\n",
        "\n",
        "x = np.expand_dims(img, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "print('Input image shape:', x.shape)\n",
        "\n",
        "my_image = imread(img_path)\n",
        "imshow(my_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzjtR44JwDY3"
      },
      "source": [
        "preds=model.predict(x)\n",
        "preds     # probabilities for being in each of the 2 classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGfhDrqTwH9t"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}