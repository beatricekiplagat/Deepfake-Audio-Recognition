{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEEPFAKE AUDIO DETECTION TRANSFER LEARNING MODELS - InceptionV3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beatricekiplagat/Deepfake-Audio-Recognition/blob/dev_branch/DEEPFAKE_AUDIO_DETECTION_TRANSFER_LEARNING_MODELS_InceptionV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Z87WeWADWr"
      },
      "source": [
        "# import necessary libraries\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvoQz_jk3bsl"
      },
      "source": [
        "#Mount google drive to access data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZi7p00eeEsZ"
      },
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "# define train and test data\n",
        "from PIL import Image\n",
        "import glob\n",
        "train_path = []\n",
        "for filename in glob.glob('/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Train/Spoof/*.png'):\n",
        "    im=Image.open(filename)\n",
        "    train_path.append(im)\n",
        "for filename in glob.glob('/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Train/Bonafide/*.png'):\n",
        "    im=Image.open(filename)\n",
        "    train_path.append(im)\n",
        "from PIL import Image\n",
        "import glob\n",
        "valid_path = []\n",
        "for filename in glob.glob('/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Test/Bonafide/*.png'):\n",
        "    im=Image.open(filename)\n",
        "    valid_path.append(im)\n",
        "for filename in glob.glob('/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Test/Spoof/*.png'):\n",
        "    im=Image.open(filename)\n",
        "    valid_path.append(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp6D02eCAS6m"
      },
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmuRcrDHDVgX"
      },
      "source": [
        "# add preprocessing layer to the front of Inception\n",
        "# the include_top false statement will allow us to be able to set the number of classes on the top layer that we will create\n",
        "incept = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "\n",
        "# don't train - incept has existing weights\n",
        "for layer in incept.layers:\n",
        "  layer.trainable = False\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOHaz19S_CXq"
      },
      "source": [
        "  # useful for getting number of classes\n",
        "  # this will count the number of classes we have in our dataset assuming that the data is grouped into specific folders\n",
        "from glob import glob\n",
        "folders = 1 #glob('/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Test/*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mb7Wdg5Doeg"
      },
      "source": [
        "# our layers\n",
        "#x = Flatten()(incept.output)\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "prediction = Dense(folders, activation='sigmoid')(x)\n",
        "\n",
        "# #adding the output layer\n",
        "# cnn.add(tf.keras.layers.Dense(units = 1 , activation = 'sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm2nFnzUDtkQ"
      },
      "source": [
        "\n",
        "# create a model object\n",
        "model = Model(inputs=incept.input, outputs=prediction)\n",
        "# view the structure of the model\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rmcUh3rD0Kr"
      },
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='binary_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# from keras.optimizers import SGD\n",
        "# opt = SGD(lr=0.01)\n",
        "# model.compile(loss = \"categorical_crossentropy\", metrics=['accuracy'], optimizer = opt)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whTKf_4O_vel"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Train/',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 4,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/DEEPFAKE AUDIO DETECTION PROJECT/DATASETS/Test/',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 4,\n",
        "                                            class_mode = 'binary')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdyuLeT8Hj8O"
      },
      "source": [
        "'''r=model.fit_generator(training_set,\n",
        "                         samples_per_epoch = 8000,\n",
        "                         nb_epoch = 5,\n",
        "                         validation_data = test_set,\n",
        "                         nb_val_samples = 2000)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bs5TjLpQkeJ"
      },
      "source": [
        "# fit the model\n",
        "r = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=5,\n",
        "  steps_per_epoch=40, #len(training_set),\n",
        "  validation_steps=40 #len(test_set)\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7aL7FYCQeYQ"
      },
      "source": [
        "# loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RAdCbCpQguA"
      },
      "source": [
        "# accuracies\n",
        "plt.plot(r.history['accuracy'], label='train accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='val accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "model.save('facefeatures_new_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kphb8ex6Qh3B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}